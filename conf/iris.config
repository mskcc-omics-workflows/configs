params {
    config_profile_description = 'IRIS profile provided for nextflow pipelines run on the IRIS cluster at MSKCC'
    config_profile_contact     = 'Nikhil Kumar (kumarn1@mskcc.org)'
    config_profile_url         = 'https://github.com/mskcc-omics-workflows/configs/blob/master/conf/iris.config'

    max_cpus          = 150
    max_memory        = 550.GB
    max_time          = 7.d

    preemptable       = true
    partition         = 'cpu'
    scratch_base      = '/scratch'
    out_base          = '/data1'
    output_prefix     = ''
}

def _get_output_prefix = {
    if (env('NXF_OUTPUT_PREFIX')) {
        return env('NXF_OUTPUT_PREFIX')
    }
    def _check_group = {
        check_group_task_command = "id -Gn | tr ' ' '\n' | grep -o -m 1 '^grp_hpc_.*' | sed 's/grp_hpc_\\(.*\\)/\\1/'"
        check_group_task = ['bash', '-c', check_group_task_command].execute()
        return check_group_task.text.trim()
    }
    def group = _check_group()
    def user = "${USER}"
    def message = ''
    if (group) {
        if (user) {
            group = "${group}/${user}"
        }
        message = "From your groups, I am using the output prefix ${group}, change this by:\n\t- Setting the NXF_OUTPUT_PREFIX environment or,\n\t- Configure it via --output_prefix"
        System.out.println(message)
        return group
    }
    if (user) {
        message = "From your username, I am using the output prefix ${user}, change this by:\n\t- Setting the NXF_OUTPUT_PREFIX environment or,\n\t- Configure it via --output_prefix"
        System.out.println(message)
    }
    return user
}

//Set sensible defaults
def output_prefix_eval  = params.output_prefix ?: _get_output_prefix()
params.outdir           = "${params.out_base}/${output_prefix_eval}/out"
params.scratch          = "${params.scratch_base}/${output_prefix_eval}/tmp"
def singularity_scratch = "${env('NXF_SINGULARITY_CACHE')?:params.scratch_base+'/'+output_prefix_eval+'/'+'singularity_scratch'}"
def singularity_library = "${env('NXF_SINGULARITY_LIBRARYDIR')?:'/data1/core006/resources/singularity_image_library'}"

workDir                 = "${params.out_base}/${output_prefix_eval}/work"

executor {
    name                = 'slurm'
    pollInterval        = 45.s
    queueSize           = 3000
    queueStatInterval   = '2 min'
    submitRateLimit     = '10 sec'
    retry.delay         = '1s'
    retry.maxDelay      = '1 min'
}

singularity {
    autoMounts          = true
    cacheDir            = singularity_scratch
    libraryDir          = singularity_library
    enabled             = true
    envWhitelist        = 'SINGULARITYENV_TMPDIR'
    pullTimeout         = 1.hour
}

// EXIT CODES for IRIS SLURM
//  - 15    wall time limit
//  - 125   out of memory
process {
    arch                = 'linux/x86_64'
    _out_of_memory      = { task -> task.previousTrace && (task.previousTrace.exit == 125 || task.previousTrace.exit == 137) }
    _out_of_time        = { task -> task.previousTrace && (task.previousTrace.exit == 15  || task.previousTrace.exit == 140) }
    _cpu_starved        = { task -> task.previousTrace && task.previousTrace['%cpu']  && task.previousTrace['%cpu']  / task.previousTrace.cpus   >= .80 }
    _near_out_of_memory = { task -> task.previousTrace && task.previousTrace.peak_rss && task.previousTrace.peak_rss / task.previousTrace.memory >= .80 }
    _near_out_of_time   = { task -> task.previousTrace && task.previousTrace.realtime && task.previousTrace.realtime / task.previousTrace.time   >= .80 }
    _get_process_memory = { first_attempt, task ->
        {
            task.attempt == 1
                ? first_attempt
            : task.attempt > 1 && process._out_of_memory(task)
                ? (task.previousTrace.memory as MemoryUnit) + (10.GB * task.attempt)
            : task.attempt > 1 && process._out_of_time(task)
                ? (task.previousTrace.memory as MemoryUnit) + (4.GB * task.attempt)
            : task.attempt > 1 && process._near_out_of_memory(task)
                ? (task.previousTrace.memory as MemoryUnit) + (4.GB * task.attempt)
            : task.attempt > 3
                ? (task.previousTrace.memory as MemoryUnit) + 10.GB
                : (task.previousTrace.memory as MemoryUnit) + 2.GB
        }
    }
    _get_process_cpus   = { first_attempt, task ->
        {
            task.attempt == 1
                ? first_attempt
            : task.attempt > 1 && process._out_of_time(task)
                ? task.previousTrace.cpus + 1
            : task.attempt > 1 && process._near_out_of_time(task)
                ? task.previousTrace.cpus + 1
            : task.attempt > 1 && process._cpu_starved(task)
                ? task.previousTrace.cpus + 2
            : task.attempt > 3
                ? task.previousTrace.cpus + 1
                : task.previousTrace.cpus
        }
    }
    _get_process_time  = { first_attempt, task ->
        {
            task.attempt == 1
                ? first_attempt
            : task.attempt > 1 && process._out_of_time(task)
                ? (task.previousTrace.time as Duration) + (12.h * task.attempt)
            : task.attempt > 1 && process._near_out_of_time(task)
                ? (task.previousTrace.time as Duration) + 12.h
            : task.attempt > 3
                ? (task.previousTrace.time as Duration) + 1.d
                : (task.previousTrace.time as Duration) + 2.h
        }
    }
    withLabel: process_single {
        cpus        = { process._get_process_cpus(1, task) }
        memory      = { process._get_process_memory(1.GB, task) }
        time        = { process._get_process_time(4.h, task) }
    }
    withLabel: process_low {
        cpus        = { process._get_process_cpus(2, task) }
        memory      = { process._get_process_memory(12.GB, task) }
        time        = { process._get_process_time(2.h, task) }
    }
    withLabel: process_medium {
        cpus        = { process._get_process_cpus(6, task) }
        memory      = { process._get_process_memory(1.MB, task) }
        time        = { process._get_process_time(8.h, task) }
    }
    withLabel: process_high {
        cpus        = { process._get_process_cpus(12, task) }
        memory      = { process._get_process_memory(72.GB, task) }
        time        = { process._get_process_time(16.h, task) }
    }
    withLabel: process_long {
        cpus        = { process._get_process_cpus(2, task) }
        memory      = { process._get_process_memory(12.GB, task) }
        time        = { process._get_process_time(20.h, task) }
    }
    withLabel: process_high_memory {
        cpus        = { process._get_process_cpus(6, task) }
        memory      = { process._get_process_memory(200.GB, task) }
        time        = { process._get_process_time(8.h, task) }
    }
    withLabel: process_gpu {
        cpus        = { process._get_process_cpus(6, task) }
        memory      = { process._get_process_memory(25.GB, task) }
        time        = { process._get_process_time(8.h, task) }
        accelerator = { 1 }
    }
    withLabel: process_gpu_low {
        cpus        = { process._get_process_cpus(6, task) }
        memory      = { process._get_process_memory(25.GB, task) }
        time        = { process._get_process_time(2.h, task) }
        accelerator = { 1 }
    }

    queue           = {
        task.time <= 2.h
                            ? 'cpushort'
                        : task.accelerator && task.time <= 2.h
                            ? 'gpushort'
                        : task.accelerator
                            ? 'gpu'
                        : task.memory >= 512.GB
                            ? 'cpu_highmem'
                        : task.memory / task.cpus >= 50.GB
                            ? 'cpu_highmem'
                        : task.attempt < 2 && params.preemptable
                            ? 'preemptable'
                        : env.NXF_SLURM_PARTITION
                            ? env.NXF_SLURM_PARTITION
                            : params.partition
    }
    resourceLimits   = [ cpus: params.max_cpus, memory: params.max_memory, time: params.max_time ]
    clusterOptions   = { task.accelerator ? "--gres=gpu:${task.accelerator.request}" : '' }
    containerOptions = {
        task.accelerator && workflow.containerEngine == 'singularity'
                            ? '--nv'
                            : task.accelerator && workflow.containerEngine == 'docker' ? '--gpus all' : ''
    }
    scratch          = params.scratch
    //Use 'lenient' if caches are not working
    cache            = true
    beforeScript     = { "unset R_LIBS; export SINGULARITYENV_JAVA_TOOL_OPTIONS='-Xms${task.memory.toMega() / 4}M -Xmx${task.memory.toGiga()}G'" }
    maxRetries       = 4
    errorStrategy    = { task.exitStatus in [143, 137, 104, 134, 139, 151, 140, 247, 12, 15, 125]
                            ? 'retry'
                        : task.exitStatus == 1 && task.attempt < 3
                            ? 'retry'
                            : 'finish'
    }
    publishDir.Mode  = 'copy'
    input.mode       = 'symlink'
    stageInMode      = 'symlink'
    stageOutMode     = 'rsync'
}

env {
    TMPDIR                = "${params.scratch}"
    SINGULARITYENV_TMPDIR = "${params.scratch}"
}

trace {
    enabled = true
}

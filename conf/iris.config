params {
    config_profile_description = 'IRIS profile provided for nextflow pipelines run on the IRIS cluster at MSKCC'
    config_profile_contact = 'Nikhil Kumar (kumarn1@mskcc.org)'
    config_profile_url = 'https://github.com/mskcc-omics-workflows/configs/blob/master/conf/iris.config'

    max_cpus = 150
    max_memory = 550.GB
    max_time = 7.d

    preemptable = true
    partition = 'cpu'
    scratch_base = '/scratch'
    out_base = '/data1'
    output_prefix = ''
}

def _get_output_prefix(){
    if (env('NXF_OUTPUT_PREFIX')) {
        return env('NXF_OUTPUT_PREFIX')
    }
    def _check_group = {
        check_group_task_command = "id -Gn | tr ' ' '\n' | grep -o -m 1 '^grp_hpc_.*' | sed 's/grp_hpc_\\(.*\\)/\\1/'"
        check_group_task = ['bash', '-c', check_group_task_command].execute()
        return check_group_task.text.trim()
    }
    def group = _check_group()
    def user = "${USER}"
    def message = ''
    if (group) {
        if (user) {
            group = "${group}/${user}"
        }
        message = "From your groups, I am using the output prefix ${group}, change this by:\n\t- Setting the NXF_OUTPUT_PREFIX environment or,\n\t- Configure it via --output_prefix"
        System.out.println(message)
        return group
    }
    if (user) {
        message = "From your username, I am using the output prefix ${user}, change this by:\n\t- Setting the NXF_OUTPUT_PREFIX environment or,\n\t- Configure it via --output_prefix"
        System.out.println(message)
    }
    return user
}

//Set sensible defaults 
def output_prefix_eval = params.output_prefix?:_get_output_prefix()
params.outdir =  "${params.out_base}/${output_prefix_eval}/out"
params.scratch = "${params.scratch_base}/${output_prefix_eval}/tmp"
def singularity_scratch = "${env('NXF_SINGULARITY_CACHE')?:params.scratch_base+"/"+output_prefix_eval+"/"+"singularity_scratch"}"
def singularity_library = "${env('NXF_SINGULARITY_LIBRARYDIR')?:'/data1/core006/resources/singularity_image_library'}"

workDir = "${params.out_base}/${output_prefix_eval}/work"

executor {
    name = 'slurm'
    pollInterval = 45.s
    queueSize = 3000
    queueStatInterval = '2 min'
    submitRateLimit   = '10 sec'
    retry.delay = '1s'
    retry.maxDelay = '1 min'
}

singularity {
    autoMounts  = true
    cacheDir    = singularity_scratch
    libraryDir  = singularity_library
    enabled     = true
    envWhitelist = 'SINGULARITYENV_TMPDIR'
    pullTimeout = 1.hour
}

// EXIT CODES for IRIS SLURM
//  - 15    wall time limit
//  - 125   out of memory
process {
    arch = 'linux/x86_64'
    memory = {
        task.attempt == 1     ? 8.GB     :
        task.attempt > 1 && task.previousTrace.exit == 125 ? task.previousTrace.memory + (10.GB * task.attempt) :
        task.attempt > 1 && task.previousTrace.exit == 15 ? task.previousTrace.memory + (4.GB * task.attempt) :
        task.attempt > 1 && task.previousTrace.peak_rss / task.previousTrace.memory >= .80 ? task.previousTrace.memory + (4.GB * task.attempt) :
        task.attempt > 3 ? task.previousTrace.memory + 25.GB :
                           task.previousTrace.memory
    }
    cpus = {
        task.attempt == 1     ? 2     :
        task.attempt > 1 && task.previousTrace.exit == 125 ? task.previousTrace.cpu :
        task.attempt > 1 && task.previousTrace.exit == 15 ? task.previousTrace.cpu + task.attempt :
        task.attempt > 1 && task.previousTrace['%cpu'] / task.previousTrace.cpus >= .80 ? task.previousTrace.cpu + 1 :
        task.attempt > 3 ? task.previousTrace.cpus + 4 :
                           task.previousTrace.cpus
    }

    time = {
        task.attempt == 1     ? 6.h     :
        task.attempt > 1 && task.previousTrace.exit == 125 ? task.previousTrace.time :
        task.attempt > 1 && task.previousTrace.exit == 15 ? task.previousTrace.time + (1.d * task.attempt) :
        task.attempt > 3 ? task.previousTrace.time + 1.d :
                           task.previousTrace.time
    }

    queue = {
        task.time <= 2.h ? 'cpushort' :
        task.accelerator && task.time <= 2.h ? 'gpushort' :
        task.accelerator ? 'gpu' :
        task.memory >= 50.GB ? 'cpu_highmem' :
        task.attempt < 2 && params.preemptable    ?   'preemptable'   :
                                                      params.partition
    }

    resourceLimits = [ cpus: params.max_cpus, memory: params.max_memory, time: params.max_time ]
    clusterOptions = { task.accelerator ? "--gres=gpu:${task.accelerator.request}" : '' }
    containerOptions = {
        task.accelerator && workflow.containerEngine == 'singularity' ? '--nv' :
        task.accelerator && workflow.containerEngine == 'docker' ? '--gpus all' : ''
    }
    scratch = params.scratch
    //Use 'lenient' if caches are not working
    cache = true
    beforeScript = { "unset R_LIBS; export SINGULARITYENV_JAVA_TOOL_OPTIONS='-Xms${task.memory.toMega()/4}M -Xmx${task.memory.toGiga()}G 'catch_term () { echo 'caught USR2/TERM signal'; set +e; false; on_exit ; } ; trap catch_term USR2 TERM" }
    maxRetries = 4
    errorStrategy = { task.exitStatus in [143, 137, 104, 134, 139, 151, 140, 247, 12, 15, 125] ? 'retry' : 'finish' }
    publishDir.Mode = 'copy'
    input.mode = 'symlink'
    stageInMode    = 'symlink'
    stageOutMode   = 'symlink'
}

env {
    TMPDIR = "${params.scratch}"
    SINGULARITYENV_TMPDIR = "${params.scratch}"
}

trace {
    enabled = true
}

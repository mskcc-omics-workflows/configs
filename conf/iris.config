params {
    config_profile_description = 'IRIS profile provided to run nextflow pipelines on the IRIS cluster at Memorial Sloan Kettering Cancer Center (MSKCC)'
    config_profile_contact     = 'Nikhil Kumar (kumarn1@mskcc.org)'
    config_profile_url         = 'https://github.com/mskcc-omics-workflows/configs/blob/master/conf/iris.config'
    max_cpus                   = 150
    max_memory                 = 550.GB
    max_time                   = 7.d
    preemptable                = false
    isolated                   = false
    group                      = ''
    array                      = 100
    qos                        = ''
    scratch_path               = '/localscratch'
    work_path                  = '/scratch'
    singularity_library        = '/data1/core006/resources/singularity_image_library'
}

validation {
    defaultIgnoreParams = ['max_cpus', 'max_memory', 'max_time', 'preemptable', 'scratch_path', 'work_path', 'singularity_library', 'isolated', 'group', 'array', 'qos', 'partition', 'scratch']
}

//Set sensible defaults
def scratch_dir         = new File(params.scratch_path)
def work_base           = new File(params.work_path + "/${params.group}")
params.partition        = params.partition                                        ?: System.getenv('NXF_SLURM_PARTITION')  ?:  'cpu'
params.scratch          = scratch_dir.exists()                                    ?  scratch_dir.getPath()                  :  "${PWD}/scratch"
workDir                 = work_base.exists() && work_base.getPath() != '/scratch' ?  work_base.getPath() + '/work'          :  "${PWD}/work"
cleanup                 = workDir.startsWith('/scratch')                          ?  true                                   :  false
def singularity_scratch = System.getenv('NXF_SINGULARITY_CACHEDIR')               ?: workDir + '/singularity_scratch'
def singularity_library = System.getenv('NXF_SINGULARITY_LIBRARYDIR')             ?: params.singularity_library

executor {
    name                = 'slurm'
    pollInterval        = 45.s
    queueSize           = 5000
    queueStatInterval   = '1 min'
    submitRateLimit     = '95/1min'
    retry.delay         = '1s'
    retry.maxDelay      = '1 min'
}

singularity {
    autoMounts          = true
    cacheDir            = singularity_scratch
    libraryDir          = singularity_library
    enabled             = true
    envWhitelist        = 'SINGULARITYENV_TMPDIR,SINGULARITYENV_JAVA_TOOL_OPTIONS'
    pullTimeout         = 1.hour
}

// EXIT CODES for IRIS SLURM
//  - 15    wall time limit
//  - 125   out of memory
process {
    arch                = 'linux/x86_64'
    array               = { process.executor == "slurm" ?  params.array : 0}
    _out_of_memory      = { task -> task.previousTrace && (task.previousTrace.exit == 125 || task.previousTrace.exit == 137) }
    _out_of_time        = { task -> task.previousTrace && (task.previousTrace.exit == 15  || task.previousTrace.exit == 140) }
    _cpu_starved        = { task -> task.previousTrace && task.previousTrace['%cpu']  && task.previousTrace['%cpu']  / task.previousTrace.cpus   >= .80 }
    _near_out_of_memory = { task -> task.previousTrace && task.previousTrace.peak_rss && task.previousTrace.peak_rss / task.previousTrace.memory >= .80 }
    _near_out_of_time   = { task -> task.previousTrace && task.previousTrace.realtime && task.previousTrace.realtime / task.previousTrace.time   >= .80 }
    _increase_memory    = { task, multiply, add -> task.previousTrace && task.previousTrace.memory ? (task.previousTrace.memory as nextflow.util.MemoryUnit) + (multiply * task.attempt) + add : task.memory + (multiply * task.attempt) + add }
    _increase_time      = { task, multiply, add -> task.previousTrace && task.previousTrace.time   ? (task.previousTrace.time as nextflow.util.Duration)     + (multiply * task.attempt) + add : task.time   + (multiply * task.attempt) + add }
    _increase_cpu       = { task, multiply, add -> task.previousTrace && task.previousTrace.cpus   ? task.previousTrace.cpus + (multiply * task.attempt) + add : task.cpus + (multiply * task.attempt) + add }
    _get_process_memory = { first_attempt, task ->
        {
            task.attempt == 1
                ? first_attempt
            : task.attempt > 1 && process._out_of_memory(task)
                ? _increase_memory(task, 10.GB, 0.GB)
            : task.attempt > 1 && process._out_of_time(task)
                ? _increase_memory(task, 4.GB, 0.GB)
            : task.attempt > 1 && process._near_out_of_memory(task)
                ? _increase_memory(task, 4.GB, 0.GB)
            : task.attempt > 3
                ? _increase_memory(task, 0.GB, 10.GB)
                : _increase_memory(task, 0.GB, 2.GB)
        }
    }
    _get_process_cpus   = { first_attempt, task ->
        {
            task.attempt == 1
                ? first_attempt
            : task.attempt > 1 && process._out_of_time(task)
                ? _increase_cpu(task, 0, 1)
            : task.attempt > 1 && process._near_out_of_time(task)
                ? _increase_cpu(task, 0, 1)
            : task.attempt > 1 && process._cpu_starved(task)
                ? _increase_cpu(task, 0, 2)
            : task.attempt > 3
                ? _increase_cpu(task, 0, 1)
                : _increase_cpu(task, 0, 0)
        }
    }
    _get_process_time  = { first_attempt, task ->
        {
            task.attempt == 1
                ? first_attempt
            : task.attempt > 1 && process._out_of_time(task)
                ? _increase_time(task, 12.h, 0.h)
            : task.attempt > 1 && process._near_out_of_time(task)
                ? _increase_time(task, 0.h, 12.h)
            : task.attempt > 3
                ? _increase_time(task, 0.h, 1.d)
                : _increase_time(task, 0.h, 2.h)
        }
    }
    withLabel: process_single {
        cpus            = { process._get_process_cpus(1, task) }
        memory          = { process._get_process_memory(1.GB, task) }
        time            = { process._get_process_time(4.h, task) }
    }
    withLabel: process_low {
        cpus            = { process._get_process_cpus(2, task) }
        memory          = { process._get_process_memory(12.GB, task) }
        time            = { process._get_process_time(2.h, task) }
    }
    withLabel: process_medium {
        cpus            = { process._get_process_cpus(6, task) }
        memory          = { process._get_process_memory(1.MB, task) }
        time            = { process._get_process_time(8.h, task) }
    }
    withLabel: process_high {
        cpus            = { process._get_process_cpus(12, task) }
        memory          = { process._get_process_memory(72.GB, task) }
        time            = { process._get_process_time(16.h, task) }
    }
    withLabel: process_long {
        cpus            = { process._get_process_cpus(2, task) }
        memory          = { process._get_process_memory(12.GB, task) }
        time            = { process._get_process_time(20.h, task) }
    }
    withLabel: process_high_memory {
        cpus            = { process._get_process_cpus(6, task) }
        memory          = { process._get_process_memory(200.GB, task) }
        time            = { process._get_process_time(8.h, task) }
    }
    withLabel: process_gpu {
        cpus            = { process._get_process_cpus(6, task) }
        memory          = { process._get_process_memory(25.GB, task) }
        time            = { process._get_process_time(8.h, task) }
        accelerator     = { 1 }
    }
    withLabel: process_gpu_low {
        cpus            = { process._get_process_cpus(6, task) }
        memory          = { process._get_process_memory(25.GB, task) }
        time            = { process._get_process_time(2.h, task) }
        accelerator     = { 1 }
    }

    queue               = {
                            params.isolated && params.preemptable
                                ? "preemptable,${params.partition}"
                            : params.isolated
                                ? params.partition
                            : task.time <= 2.h
                                ? "cpushort,cpu,${params.partition}"
                            : task.accelerator && task.time <= 2.h
                                ? 'gpushort,gpu'
                            : task.accelerator
                                ? 'gpu'
                            : task.memory >= 512.GB
                                ? "cpu_highmem,cpu,${params.partition}"
                            : task.memory / task.cpus >= 50.GB
                                ? "cpu_highmem,cpu,${params.partition}"
                            : task.attempt < 2 && params.preemptable
                                ? "preemptable,cpu,${params.partition}"
                                : params.partition
    }
    resourceLimits      = [ cpus: params.max_cpus, memory: params.max_memory, time: params.max_time ]
    clusterOptions      = {
                            task.accelerator && params.qos
                                ? "--qos=${params.qos} --gres=gpu:${task.accelerator.request}"
                            : task.accelerator
                                ? "--gres=gpu:${task.accelerator.request}"
                            : params.qos
                                ? "--qos=${params.qos}"
                                : ''
    }
    containerOptions    = {
                            task.accelerator && workflow.containerEngine == 'singularity'
                                ? '--nv'
                            : task.accelerator && workflow.containerEngine == 'docker'
                                ? '--gpus all'
                                : ''
    }
    scratch             = params.scratch
    //Use 'lenient' if caches are not working
    cache               = true
    beforeScript        = { "unset R_LIBS; export SINGULARITYENV_TMPDIR=$NXF_SCRATCH; export SINGULARITYENV_TMP=$NXF_SCRATCH; export SINGULARITYENV_JAVA_TOOL_OPTIONS='-Djava.io.tmpdir=$NXF_SCRATCH -Xms${task.memory.toMega() / 4}M -Xmx${task.memory.toGiga()}G'" }
    maxRetries          = 4
    errorStrategy       = {
                            task.exitStatus in [143, 137, 104, 134, 139, 151, 140, 247, 12, 15, 125]
                                ? 'retry'
                            : task.exitStatus == 1 && task.attempt < 3
                                ? 'retry'
                                : 'finish'
    }
    publishDir.Mode     = 'copy'
    input.mode          = 'symlink'
    stageInMode         = 'symlink'
    stageOutMode        = 'copy'
}

workflow.output.mode    = 'copy'

env {
    TMP                   = "${params.scratch}"
    TMPDIR                = "${params.scratch}"
    SINGULARITYENV_TMPDIR = "${params.scratch}"
}

trace {
    enabled = true
}

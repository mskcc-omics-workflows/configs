params {
    config_profile_description = 'IRIS profile provided to run nextflow pipelines on the IRIS cluster at Memorial Sloan Kettering Cancer Center (MSKCC)'
    config_profile_contact     = 'Nikhil Kumar (kumarn1@mskcc.org)'
    config_profile_url         = 'https://github.com/mskcc-omics-workflows/configs/blob/master/conf/iris.config'
    max_cpus                   = 150
    max_memory                 = 550.GB
    max_time                   = 7.d
    preemptable                = false
    output_prefix              = ''
    local_scratch_path         = '/localscratch'
    data_path                  = '/data1'
    work_path                  = '/scratch'
    singularity_library        = '/data1/core006/resources/singularity_image_library'
}

validation {
    defaultIgnoreParams = ['max_cpus', 'max_memory', 'max_time', 'preemptable', 'output_prefix', 'local_scratch_path', 'data_path', 'work_path', 'singularity_library', 'partition', 'scratch']
}

def _get_output_prefix = {
    if (System.getenv('NXF_OUTPUT_PREFIX')) {
        return System.getenv('NXF_OUTPUT_PREFIX')
    }

    local_scratch_dir   = new File(params.local_scratch_path)
    data_dir            = new File(params.data_path)
    work_dir            = new File(params.work_path)

    if (!local_scratch_dir.exists() && !data_dir.exists() && !work_dir.exists()) {
        return ''
    }
    def _check_group = {
        check_group_task_command = "id -Gn | tr ' ' '\n' | grep -o -m 1 '^grp_hpc_.*' | sed 's/grp_hpc_\\(.*\\)/\\1/'"
        check_group_task         = ['bash', '-c', check_group_task_command].execute()
        return check_group_task.text.trim()
    }
    def _print_info_message = { output_prefix ->
        {
        message = """From your groups, I am using the output prefix ${output_prefix}, change this by:
                        | - Setting the 'NXF_OUTPUT_PREFIX' environment or,
                        | - Configure it via '--output_prefix'
        """.stripMargin().stripIndent()
        System.out.println(message)
        }
    }
    def group   = _check_group()
    def user    = "${USER}"
    if (group) {
        if (user) {
            group = "${group}/${user}"
        }
        _print_info_message(group)
        return group
    }
    if (user) {
        _print_info_message(user)
    }
    return user
}

//Set sensible defaults
def local_scratch_dir   = new File(params.local_scratch_path)
def data_dir            = new File(params.data_path)
def work_dir            = new File(params.work_path)
def output_prefix_eval  = params.output_prefix                           ?: _get_output_prefix()
params.partition        = params.partition                               ?: System.getenv('NXF_SLURM_PARTITION')  ?: 'cpu'
params.scratch          = local_scratch_dir.exists()                     ? "${local_scratch_dir.getPath()}/${output_prefix_eval}/scratch"  :  "${PWD}/scratch"
outdir                  = data_dir.exists()                              ? "${data_dir.getPath()}/${output_prefix_eval}/out"               :  "${PWD}/out"
workDir                 = work_dir.exists()                              ? "${work_dir.getPath()}/${output_prefix_eval}/work"              :  "${PWD}/work"
params.outdir           = outdir
def singularity_scratch = "${System.getenv('NXF_SINGULARITY_CACHE')      ?: workDir+'/'+'singularity_scratch'}"
def singularity_library = "${System.getenv('NXF_SINGULARITY_LIBRARYDIR') ?: params.singularity_library}"

executor {
    name                = 'slurm'
    pollInterval        = 45.s
    queueSize           = 3000
    queueStatInterval   = '2 min'
    submitRateLimit     = '10 sec'
    retry.delay         = '1s'
    retry.maxDelay      = '1 min'
}

singularity {
    autoMounts          = true
    cacheDir            = singularity_scratch
    libraryDir          = singularity_library
    enabled             = true
    envWhitelist        = 'SINGULARITYENV_TMPDIR,SINGULARITYENV_JAVA_TOOL_OPTIONS'
    pullTimeout         = 1.hour
}

// EXIT CODES for IRIS SLURM
//  - 15    wall time limit
//  - 125   out of memory
process {
    arch                = 'linux/x86_64'
    _out_of_memory      = { task -> task.previousTrace && (task.previousTrace.exit == 125 || task.previousTrace.exit == 137) }
    _out_of_time        = { task -> task.previousTrace && (task.previousTrace.exit == 15  || task.previousTrace.exit == 140) }
    _cpu_starved        = { task -> task.previousTrace && task.previousTrace['%cpu']  && task.previousTrace['%cpu']  / task.previousTrace.cpus   >= .80 }
    _near_out_of_memory = { task -> task.previousTrace && task.previousTrace.peak_rss && task.previousTrace.peak_rss / task.previousTrace.memory >= .80 }
    _near_out_of_time   = { task -> task.previousTrace && task.previousTrace.realtime && task.previousTrace.realtime / task.previousTrace.time   >= .80 }
    _increase_memory    = { task, multiply, add -> task.previousTrace && task.previousTrace.memory ? (task.previousTrace.memory as nextflow.util.MemoryUnit) + (multiply * task.attempt) + add : task.memory + (multiply * task.attempt) + add }
    _increase_time      = { task, multiply, add -> task.previousTrace && task.previousTrace.time   ? (task.previousTrace.time as nextflow.util.Duration)     + (multiply * task.attempt) + add : task.time   + (multiply * task.attempt) + add }
    _increase_cpu       = { task, multiply, add -> task.previousTrace && task.previousTrace.cpus   ? task.previousTrace.cpus + (multiply * task.attempt) + add : task.cpus + (multiply * task.attempt) + add }
    _get_process_memory = { first_attempt, task ->
        {
            task.attempt == 1
                ? first_attempt
            : task.attempt > 1 && process._out_of_memory(task)
                ? _increase_memory(task, 10.GB, 0.GB)
            : task.attempt > 1 && process._out_of_time(task)
                ? _increase_memory(task, 4.GB, 0.GB)
            : task.attempt > 1 && process._near_out_of_memory(task)
                ? _increase_memory(task, 4.GB, 0.GB)
            : task.attempt > 3
                ? _increase_memory(task, 0.GB, 10.GB)
                : _increase_memory(task, 0.GB, 2.GB)
        }
    }
    _get_process_cpus   = { first_attempt, task ->
        {
            task.attempt == 1
                ? first_attempt
            : task.attempt > 1 && process._out_of_time(task)
                ? _increase_cpu(task, 0, 1)
            : task.attempt > 1 && process._near_out_of_time(task)
                ? _increase_cpu(task, 0, 1)
            : task.attempt > 1 && process._cpu_starved(task)
                ? _increase_cpu(task, 0, 2)
            : task.attempt > 3
                ? _increase_cpu(task, 0, 1)
                : _increase_cpu(task, 0, 0)
        }
    }
    _get_process_time  = { first_attempt, task ->
        {
            task.attempt == 1
                ? first_attempt
            : task.attempt > 1 && process._out_of_time(task)
                ? _increase_time(task, 12.h, 0.h)
            : task.attempt > 1 && process._near_out_of_time(task)
                ? _increase_time(task, 0.h, 12.h)
            : task.attempt > 3
                ? _increase_time(task, 0.h, 1.d)
                : _increase_time(task, 0.h, 2.h)
        }
    }
    withLabel: process_single {
        cpus        = { process._get_process_cpus(1, task) }
        memory      = { process._get_process_memory(1.GB, task) }
        time        = { process._get_process_time(4.h, task) }
    }
    withLabel: process_low {
        cpus        = { process._get_process_cpus(2, task) }
        memory      = { process._get_process_memory(12.GB, task) }
        time        = { process._get_process_time(2.h, task) }
    }
    withLabel: process_medium {
        cpus        = { process._get_process_cpus(6, task) }
        memory      = { process._get_process_memory(1.MB, task) }
        time        = { process._get_process_time(8.h, task) }
    }
    withLabel: process_high {
        cpus        = { process._get_process_cpus(12, task) }
        memory      = { process._get_process_memory(72.GB, task) }
        time        = { process._get_process_time(16.h, task) }
    }
    withLabel: process_long {
        cpus        = { process._get_process_cpus(2, task) }
        memory      = { process._get_process_memory(12.GB, task) }
        time        = { process._get_process_time(20.h, task) }
    }
    withLabel: process_high_memory {
        cpus        = { process._get_process_cpus(6, task) }
        memory      = { process._get_process_memory(200.GB, task) }
        time        = { process._get_process_time(8.h, task) }
    }
    withLabel: process_gpu {
        cpus        = { process._get_process_cpus(6, task) }
        memory      = { process._get_process_memory(25.GB, task) }
        time        = { process._get_process_time(8.h, task) }
        accelerator = { 1 }
    }
    withLabel: process_gpu_low {
        cpus        = { process._get_process_cpus(6, task) }
        memory      = { process._get_process_memory(25.GB, task) }
        time        = { process._get_process_time(2.h, task) }
        accelerator = { 1 }
    }

    queue           = {
        task.time <= 2.h
                            ? "cpushort,cpu,${params.partition}"
                        : task.accelerator && task.time <= 2.h
                            ? 'gpushort,gpu'
                        : task.accelerator
                            ? 'gpu'
                        : task.memory >= 512.GB
                            ? "cpu_highmem,cpu,${params.partition}"
                        : task.memory / task.cpus >= 50.GB
                            ? "cpu_highmem,cpu,${params.partition}"
                        : task.attempt < 2 && params.preemptable
                            ? "preemptable,cpu,${params.partition}"
                            : params.partition
    }
    resourceLimits   = [ cpus: params.max_cpus, memory: params.max_memory, time: params.max_time ]
    clusterOptions   = { task.accelerator ? "--gres=gpu:${task.accelerator.request}" : '' }
    containerOptions = {
        task.accelerator && workflow.containerEngine == 'singularity'
                            ? '--nv'
                            : task.accelerator && workflow.containerEngine == 'docker' ? '--gpus all' : ''
    }
    scratch          = params.scratch
    //Use 'lenient' if caches are not working
    cache            = true
    beforeScript     = { "unset R_LIBS; export SINGULARITYENV_TMPDIR=$NXF_SCRATCH; export SINGULARITYENV_TMP=$NXF_SCRATCH; export SINGULARITYENV_JAVA_TOOL_OPTIONS='-Djava.io.tmpdir=$NXF_SCRATCH -Xms${task.memory.toMega() / 4}M -Xmx${task.memory.toGiga()}G'" }
    maxRetries       = 4
    errorStrategy    = { task.exitStatus in [143, 137, 104, 134, 139, 151, 140, 247, 12, 15, 125]
                            ? 'retry'
                        : task.exitStatus == 1 && task.attempt < 3
                            ? 'retry'
                            : 'finish'
    }
    publishDir.Mode  = 'copy'
    input.mode       = 'symlink'
    stageInMode      = 'symlink'
    stageOutMode     = 'rsync'
}

workflow.output.mode = 'copy'

env {
    TMP                   = "${params.scratch}"
    TMPDIR                = "${params.scratch}"
    SINGULARITYENV_TMPDIR = "${params.scratch}"
}

trace {
    enabled = true
}
